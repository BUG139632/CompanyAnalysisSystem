#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¸»ç¨‹åºå…¥å£
"""
from crawler_agent.company_data_collector import (
    collect_single_company_data
)
from data_clean_agent.data_clean_agent import DataCleanAgent
from analysis_agent.analysis_agent import run_interactive_analysis


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å…¬å¸æ•°æ®é‡‡é›†ä¸æ¸…æ´—ç³»ç»Ÿå¯åŠ¨")
    print("=" * 50)
    
    # ç”¨æˆ·äº¤äº’è¾“å…¥å…¬å¸åç§°
    user_input = input("è¯·è¾“å…¥ç›®æ ‡å…¬å¸åç§°ï¼š\n> ").strip()
    if not user_input:
        print("æœªè¾“å…¥æœ‰æ•ˆå…¬å¸åç§°ï¼Œç¨‹åºé€€å‡ºã€‚")
        return
    test_companies = [user_input]
    

    print(f"\nğŸ¯ å¼€å§‹é‡‡é›†å…¬å¸æ•°æ®: {test_companies[0]}")
    result = collect_single_company_data(test_companies[0])
    print(f"âœ… é‡‡é›†å®Œæˆ: {result['company_name']}")
    
    # æ•°æ®æ¸…æ´—å’Œç»“æ„åŒ–å¤„ç†
    print(f"\nğŸ§¹ å¼€å§‹æ•°æ®æ¸…æ´—å’Œç»“æ„åŒ–å¤„ç†...")
    print("=" * 50)
    
    try:
        # åˆå§‹åŒ–æ•°æ®æ¸…æ´—ä»£ç†
        clean_agent = DataCleanAgent(config_path="config/langchain_config.yaml")
        
        # æ‰§è¡Œå®Œæ•´çš„æ¸…æ´—å’Œåˆå¹¶æµç¨‹
        clean_agent.run_full_clean_and_merge()
        
        print(f"\nğŸ‰ æ•°æ®æ¸…æ´—å’Œç»“æ„åŒ–å¤„ç†å®Œæˆï¼")
        print("ğŸ“ è¾“å‡ºæ–‡ä»¶ä½ç½®:")
        print("   - åˆå¹¶è´¢æŠ¥: data/structured/all_merged_financial_reports.json")
        print("   - å…¬å‘Šä¿¡æ¯: data/structured/all_announcements_structured.json")
        print("   - ç ”æŠ¥ä¿¡æ¯: data/structured/all_reports_structured.json")
        
    except Exception as e:
        print(f"âŒ æ•°æ®æ¸…æ´—è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        print("è¯·æ£€æŸ¥æ•°æ®æºå’Œé…ç½®æ˜¯å¦æ­£ç¡®")

    # è¿è¡Œäº¤äº’å¼åˆ†æç³»ç»Ÿ 
    print("\nğŸ§  å¯åŠ¨å…¬å¸æ¨¡å¼åˆ†æç³»ç»Ÿ...")
    run_interactive_analysis()

if __name__ == "__main__":
    main()
